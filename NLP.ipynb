{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSTXbLjfT2B2RoCvW05MfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gontay/capstone-projv2/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just my attempt to understand NLP and explore Language with ML and NN."
      ],
      "metadata": {
        "id": "Es7FHWj-6dcu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goals:\n",
        "1. Identify optimal format for speech samples.\n",
        "2. Identify medium of data for learning raw unprocessed vs image(Spectogram and Waveform)\n",
        "3. Apply NN or ML\n",
        "4. Get emotional tone from soundbite"
      ],
      "metadata": {
        "id": "yYUA4qLd64oJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theory Crafting\n",
        "\n",
        "## Analog Audio\n",
        "Analog Audio is hard to explain b'cos I'm small brained. But essentially the sounds are not processed in anyway by a computer so in theory you just get the sound as it is. Imagine this sentence as a smooth line with of word going into your ear.\n",
        "\n",
        "`\"I am a bad explainer of things but I try my best.\"`\n",
        "\n",
        "## Digital Audio\n",
        "Digital Audio is audio but digital. So digital introduces a hypotetical information lost due to the limitation computers. Imagine that the sentence took 10 seconds to complete and you took 1 small sample every second for this example. It would look something like this.\n",
        "\n",
        "`\"I a ad expl of ings ut I tr m est\"`\n",
        "\n",
        "### *Sampling Rate*\n",
        "Now what if I take more samples every second? I collect more information as I have more samples in each second. So I it might look something like this:\n",
        "\n",
        "`\"I m a bd explain of thing bu I tr my bes\"`"
      ],
      "metadata": {
        "id": "ivFTxOFd8spM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for Audio Input"
      ],
      "metadata": {
        "id": "QDdgoatkJstq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Record and playback\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "from io import BytesIO\n",
        "!pip -q install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  audio = AudioSegment.from_file(BytesIO(b))\n",
        "  return audio"
      ],
      "metadata": {
        "id": "XWBr4ggXMSzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Record and save\n",
        "from IPython.display import Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record_save(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  with open('audio.wav','wb') as f:\n",
        "    f.write(b)\n",
        "  return 'audio.wav'  # or webm ?"
      ],
      "metadata": {
        "id": "Q97FvbUEJ46c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eD-Y4iGiNmCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "632c00b6-7941-40ea-84a1-ea3732c835b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'audio.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}